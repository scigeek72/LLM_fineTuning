# LLM_fineTuning
Resources on fine tuning LLMs on specific set of data

## Specific quotes from "Fine Tuning Large Language Models" By S.Raschka 

--[Different ways to use LLMs for specific data](https://open.substack.com/pub/sebastianraschka/p/finetuning-large-language-models?r=3vdx8&selection=09194600-1336-4b6d-8f35-48bf0528f559&utm_campaign=post-share-selection&utm_medium=web) by Raschka

--[LLM Fine Tunning ](https://open.substack.com/pub/sebastianraschka/p/finetuning-large-language-models?r=3vdx8&selection=b25098cb-abf4-4638-a138-6c6c40583b60&utm_campaign=post-share-selection&utm_medium=web) by  Raschka

-- There are two(2) types of LLMs: 1) Encoder type (BERT) 2) Decoder type (GPT)

-- Encoder type LLM is more suitable for Classification task (???) while Decoder type LLMs are more suitable for sentence generation (...WARNING: Verify this statement ... )

-- For large LLMs, such as the latest generative models, we can use "[Performance Efficient Fine Tuning approach]"(https://open.substack.com/pub/sebastianraschka/p/finetuning-large-language-models?r=3vdx8&selection=e351cc70-a86c-455d-8a90-281fd590ef85&utm_campaign=post-share-selection&utm_medium=web).

-- 

## About LLMs

-- [A very nice set of papers for getting into LLMs](https://www.linkedin.com/feed/update/urn:li:activity:7028449312300834816?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7028449312300834816%2C7028519126105030656%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287028519126105030656%2Curn%3Ali%3Aactivity%3A7028449312300834816%29) By S. Raschka

-- [Building LLM application for production](https://huyenchip.com/2023/04/11/llm-engineering.html) by Chip Huyen
